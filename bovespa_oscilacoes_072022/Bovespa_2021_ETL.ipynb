{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center>EXTRAÇÃO, TRATAMENTO E MODELAGEM DOS DADOS DA BOLSA DE VALORES BRASILEIRA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<P>O objetivo deste artigo é ensinar passo a passo como extrair e modelar os dados da bolsa de valores, utilizando a linguagem de programação Python e a biblioteca Pandas. Então, o primeiro passo é entender que tipo de dados estamos procurando. Porque, dentro do site da B3, exitem diversos DataSets para análise.\n",
    "Sugiro pesquisar no site oficial as opções disponíveis: https://www.b3.com.br/pt_br/market-data-e-indices/servicos-de-dados/market-data/historico/\n",
    "Aqui, utilizaremos os dados do último mês disponível (07/2022) e posteriormente vamos automatizar o código que faremos hoje, para que ele seja atualizado automaticamente.\n",
    "\n",
    "<img src='txt_img_0722.jpg'></img>\n",
    "\n",
    "Temos então, um arquivo txt com dados semiestruturados pois, eles não possuem uma estrutura clara porém, possuem delimitações que permitirão a estruturação dos dados para utilização por exemplo, no Power BI ou Excell.\n",
    "Lembrando que este é um estudo da linguagem Python, vamos começar importando a biblioteca Pandas, que será a única utilizada neste artigo.\n",
    "Não se esqueça de instalar a biblioteca dentro do seu editor de códigos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Antes de importar os dados, precisamos saber quais dados nós estamos procurando e quais dados estão disponíveis no arquivo TXT. Para isso, existe uma documentação chamada de Layout cujas informações nortearão nossa busca. No caso da Bovespa, existe um arquivo pdf disponível na página de históricos.\n",
    "Para este artigo, utilizaremos:\n",
    "- A data do Pregão;\n",
    "- O código da ação;\n",
    "- O nome da empresa;\n",
    "- O preço de abertura das ações;\n",
    "- O preço máximo negociado;\n",
    "- O preço mínimo negociado;\n",
    "- O preço de fechamento das ações;\n",
    "- A quantidade de negócios;\n",
    "- O volume financeiro negociado;\n",
    "\n",
    "Também, no caso das ações da Bovespa e para o nosso estudo, precisamos entender que os dados relevantes serão as negociações por lote padrão. Entretanto, poderíamos por exemplo, buscar também as negociações no mercado fracionário afim de estudar correlações entre os mercados. Por fim, entendemos que o arquivo da Bovespa trata-se de um arquivo de dados em formato de largura fixa então, neste artigo iremos uilizar a função read.fwf para importar os dados que vamos utilizar.\n",
    "Para começar, vamos criar duas listas, uma contendo os valores da largura do texto do nosso DataSet e outra com os nomes das variáveis que deverão receber esses valores.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = [(2,10), (10,12), (12,24), (27,39), \n",
    "(56,69),(69,82),(82,95),\n",
    "(108,121),(152,170),(170,188)]\n",
    "\n",
    "name_table = ['data_pregao','cod_bdi', 'cod_acao', 'nome_emp', 'preco_abertura', 'preco_maximo', 'preco_minimo', \n",
    "'preco_fechamento', 'qtd_negocios', 'vol_financeiro']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importante! As informações da variável 'table' foram fornecidas pelo pdf com as informações de layout citadas anteriormente neste artigo.\n",
    "\n",
    "Finalmente, podemos aplicar o método read fwf para importar os dados necessários e criar o nosso DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_table = pd.read_fwf(\"./Arquivos/hist_ult12meses_a_vista_072022.TXT\", colspecs = table,\n",
    "names = name_table, skiprows=1)\n",
    "display(df_table)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Já temos o nosso primeiro DataBase, podemos notar que ainda não é uma tabela pronta para usarmos em análises pois, existe ainda muita informação não filtradas. Então, nesta primeira parte da limpeza dos dados, vamos filtrar o 'cod_bdi' que, conforme explicado no arquivo de layout, traz o filtro de mercado à vista que são os valores que queremos analisar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_table = df_table[df_table['cod_bdi'] == 2]\n",
    "display(df_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora, temos a tabela com os valores que desejamos utilizar. Portanto, vamos fazer alguns tratamentos para limpar os dados e corrigir os tipos dos valores importados. Porque, apesar dos valores já estarem organizados em colunas, a formatação ainda está errada então, vamos transformar os valores de data em data, excluir o cod_bdi que já utilizamos e transformar os números para a tipagem correta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_table = df_table.drop(['cod_bdi'], axis=1)\n",
    "df_table['data_pregao'] = pd.to_datetime(df_table['data_pregao'], format='%Y%m%d')\n",
    "df_table['preco_abertura'] = (df_table['preco_abertura']/100).astype(float)\n",
    "df_table['preco_maximo'] = (df_table['preco_maximo']/100).astype(float)\n",
    "df_table['preco_minimo'] = (df_table['preco_minimo']/100).astype(float)\n",
    "df_table['preco_fechamento'] = (df_table['preco_fechamento']/100).astype(float)\n",
    "df_table['qtd_negocios'] = df_table['qtd_negocios'].astype(int)\n",
    "df_table['vol_financeiro'] = df_table['vol_financeiro'].astype(int)\n",
    "df_table['nome_emp'] = df_table['nome_emp'].astype(str)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concluímos a primeira parte da nossa tarefa de extração dos dados.\n",
    "Vou criar uma nova variável, contendo as informações desta tabela para continuar com a limpeza dos dados. Faço isso, para o caso de precisar verificar a tabela inicial em algum momento porque assim, sempre tenho as primeiras informações disponíveis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_table\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A primeira coisa que é importante fazer, é analisar as primeiras possibilidades de erros nas informações e para isso, vamos fazer algumas análises gerais dos valores da tabela como, número de colunas e linhas, informações gerais, se existem valores nulos e possíveis discrepâncias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#display(df.shape)\n",
    "#df.isnull().sum()\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Já sabemos agora, que o número de linhas é de 17607, não há valores nulos e na descrição existe uma informação importante para verificarmos. No 'max' que mostra os valores máximos de cada coluna, temos uma ação que foi negociada a R$98.335,00 enquanto, a média está em torno de R$100,00.\n",
    "Vamos verificar este valor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values(by =['preco_abertura'], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como imaginado, o valor discrepante é referente ao IBOV, que é um dado importante porém, não é o foco do nosso estudo. Por isso, vamos excluir a linha que consta o IBOV11 também, podemos ver que existem ações que não tiveram negocios no mercado à vista então, vamos excluir aas linhas com valores de 'qtd_negocios' zerados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop([19087],inplace=True)\n",
    "no_exchange_df = df[df['qtd_negocios'] == 0]\n",
    "df = df.drop(no_exchange_df.index)\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Temos então, uma tabela em que todas as ações tiveram alguma operação no período.\n",
    "A partir daqui, é importante termos uma boa ideia do que queremos analisar para melhorar ainda mais os dados portanto, vou adicionar duas colunas com o valor percentual de variação das ações, uma para os valores de abertura e fechamento e outro, para os valores máximo e mínimo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['perc_fechamento'] = ((df['preco_fechamento'] / df['preco_abertura'])-1)*100\n",
    "df['perc_max'] = ((df['preco_minimo'] / df['preco_maximo'])-1)*(-100)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uma vez que temos esses novos dados, podemos fazer uma análise que eu julgo interessante. Quantas ações e dias a variação diária de ações que tiveram negócios foi zero ou seja, quando fecharam no mesmo valor de abertura.\n",
    "Vamos salvar este filtro e retirar as ações que tiveram este comportamento para continuar nossos estudos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_a_zero_df = df[df['perc_fechamento']==0]\n",
    "#zero_a_zero_df.to_csv('zeroazero.csv')\n",
    "df = df.drop(zero_a_zero_df.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente, vamos fazer a extração das 10 ações que tiveram maior e menor percentual de variação diária neste período."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "major_perc_df = df.nlargest(n=20, columns='perc_fechamento', keep='all')\n",
    "minor_perc_df = df.nsmallest(n=20, columns='perc_fechamento', keep='all')\n",
    "major_perc_df.to_csv('maiores_perc_var_072022.csv')\n",
    "minor_perc_df.to_csv('menores_perc_var_072022.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obrigado e parabéns por ter chegado até aqui, espero que este artigo tenha trazido informações úteis para o seu aprendizado. Mas, o trabalho ainda não acabou. \n",
    "Vamos agora, construir um Dashboard no Power BI para mostrar nossas análises de forma clara e impactante.\n",
    "Logo logo, farei um artigo onde irei mostrar como transformar os passos feitos hoje em funções, para serem aplicados nos mais diversos DataSets."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2d0abe5f30a15a1a2dcd598f175e84b4219c221b6dc35ac637f623bca44c8a0c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
